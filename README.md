# Predicting Natural Disasters

Natural disasters have a multitude of factors involved in their detection, some of the natural disasters are earthquakes, tsunami, hurricane, volcanic eruption, avalanche and landslide. Like a disease gives out cues before actually showing up, so do these disasters. Catching those cues can thus enable us to predict the disaster. So here comes the machine learning into the picture as machine learning enables to analyse all the patterns and predicts the outcome. 

Training a model to predict these disasters would involve at first to identify all the available data so that a better prediction can be made. I was going through the research of the google's self driving car and why is it so ahead of its competitors. It was because of the fact that they were collecting a lot of data, about 1 GB of data for enabling it to drive autonoumously. With a multitude of sensors and data fusion has enabled it to perform a lot better. After reading about it furthur the car was collecting data that felt seeming unrelated to the art of driving at first to humans but the data has proven to be useful. So the same goes in capturing features as if we think that certain features are directly involved into the prediction but there certainly could be many latent ones. Thus for example say we choose to predict hurricane, in this wind speed, direction, humidity are certain factors that are directly involved with the disasters but some latent onese could be the attenuation the sound because of the changing medium can be captured to understand more about the disaster, but again obtaining such data can be a daunting task given the fact that we cannot install addiction sensors and have to rely purely on the commonly available meteorological data. Though our main focus would be to obtain as much data as possible so that a smarter algorithm can be developed. The main focus would be to obtain the data that was collected when the disaster actually occured as though training an algorithm for unsupervised learning is possible but that has some loopholes to it. 

How would our model be different? 
Now this question can be answered by the fact that the along with all the features that are conventionally used I have thought about going a step furthur and analysing the images of the area before, after, during the disaster by training a CNN and using this as an additional feature with the data from the meterological department. Image speaks a thousand words and it is true as this data is so humongous and widely available of every area that we can think about. As a continous obsevation would be done on the images of the area, latent signs can be learned by the model that can thus be captured. It could be the colour of the sky, the shape of the sounds, the positions of the trees leaves flushed with the wind, etc.Similar analysis can be done from of the videos that are publicly uploaded by the users thus capturing the sound of the wind and things like that.

For places that are not so well connected with the internet, for such places we can observe the satellite image data and obtain the prediciton, though the same would be done for above as well but this could additionally be worked upon on the above case as well. One aspect that I feel is can be game changing in the prediciton is if we get the cellular data, as during disaster suddenly a lot of disturbances is observed in the network and as a lot of people have mobile phones this can be used well. To observe increase in the crowd in a particular location or sudden loss of signal. 

The alorithms would be LSTM to observe the time scale data, CNN for images and all the work would be done on pytorch. The data would be obtained from all the major meterological departments, weather satellites data, some of the cities have region specific weather data etc. 
For earthquake prediction the data about the tectonic plates and there positioning before, after and during the disaster is available which can be put to use. 
